{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcTimeStamps(startDaysAgo: int, endDaysAgo: int) -> '[startStamp, endStamp]':\n",
    "    \"\"\"Returns timestamps for set days from the past\"\"\"\n",
    "    now = datetime.now()\n",
    "\n",
    "    # Datetimes calculation\n",
    "    dateStart = now - timedelta(days=startDaysAgo)\n",
    "    dateEnd = now - timedelta(days=endDaysAgo)\n",
    "\n",
    "    # Datetimes to timestamps conversion\n",
    "    stampStart = int(datetime.timestamp(dateStart))\n",
    "    stampEnd = int(datetime.timestamp(dateEnd))\n",
    "\n",
    "    return [stampStart, stampEnd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPushShiftData(afterDateStamp: \"Start timestamp\", beforeDateStamp: \"End timestamp\", subredditName: \"Subreddit's name\"):\n",
    "    \"\"\"Returns a dictionary based on JSON object received from PushShift's API\"\"\"\n",
    "    # API's querries are being made through URL\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?' + 'size=500' + '&after=' + str(afterDateStamp) + '&before=' + \\\n",
    "            str(beforeDateStamp) + '&subreddit=' + str(subredditName)\n",
    "    # Get a request from the url\n",
    "    request = requests.get(url)\n",
    "    # Load and convert: JSON -> dictionary\n",
    "    data = json.loads(request.text)\n",
    "\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectDataFromSubmission(submissionsList: 'list of json-origin dictionaries', yummyDataDictionary: 'a dictionary the data is being appended to'):\n",
    "    \"\"\"Gets specific data from every submission and appends it to the yummyDataDictionary\"\"\"\n",
    "    for submission in submissionsList:\n",
    "        title = submission['title']\n",
    "        url = submission['url']\n",
    "        try:\n",
    "            flair = submission['link_flair_text']\n",
    "        except KeyError:\n",
    "            flair = np.nan\n",
    "        author = submission['author']\n",
    "        subId = submission['id']\n",
    "        score = submission['score']\n",
    "        created = datetime.fromtimestamp(submission['created_utc'])\n",
    "        numComments = submission['num_comments']\n",
    "        permalink = submission['permalink']\n",
    "\n",
    "        # Structuring the data\n",
    "        dataChunk = (subId, title, url, author, score, created, numComments, permalink, flair)\n",
    "\n",
    "        yummyDataDictionary[subId] = dataChunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forceGetData(afterDateStamp: \"Start timestamp\", beforeDateStamp: \"End timestamp\", subredditName: \"Subreddit's name\"):\n",
    "    \"\"\"Forces Pushshift API to return more submissions (over 500) by pushing multiple querries. Those have to be time delayed, so that requests_limit per minute is not exceeded\"\"\"\n",
    "    # Stores all the colleced entries\n",
    "    finalDictionary = {}\n",
    "\n",
    "    # Get the first chunk of data\n",
    "    dataChunk = getPushShiftData(afterDateStamp, beforeDateStamp, subredditName)\n",
    "\n",
    "    \n",
    "    # While data is still being received\n",
    "    while len(dataChunk) > 0:\n",
    "        # Collect interesting fields\n",
    "        collectDataFromSubmission(dataChunk, finalDictionary)\n",
    "\n",
    "        # Narrow the time frame\n",
    "        newAfterStamp = dataChunk[-1]['created_utc']\n",
    "        # Querry again\n",
    "        dataChunk = getPushShiftData(newAfterStamp, beforeDateStamp, subredditName)\n",
    "\n",
    "        # Periodic output for users comfort\n",
    "        date = datetime.fromtimestamp(newAfterStamp)\n",
    "        print(f\"Current date: {date}\")\n",
    "        # Cannot exceed 120 querries per minute\n",
    "        # No problem, my internet connection is too slow\n",
    "        time.sleep(0.25)\n",
    "\n",
    "    return finalDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeDataToCSV(dataDictionary: 'dict with all the yummy data', fileName='default.csv'):\n",
    "    \"\"\"Writes the collected data to a .csv file\"\"\"\n",
    "    with open(fileName, 'w', newline='', encoding='utf-8') as file:\n",
    "        csvWriter = csv.writer(file, delimiter=',')\n",
    "\n",
    "        # Adding a header\n",
    "        headers = [\"Post ID\", \"Title\", \"URL\", \"Author\", \"Score\", \"Publish Date\", \"Total number of comments\", \"Permalink\", \"Flair\"]\n",
    "        csvWriter.writerow(headers)\n",
    "\n",
    "        # Writing the data\n",
    "        for sub in dataDictionary:\n",
    "            csvWriter.writerow(dataDictionary[sub])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc timestamps for begin & end days\n",
    "datesList  = calcTimeStamps(1,91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Current date: 2019-12-27 02:47:28\nCurrent date: 2019-12-27 18:32:06\nCurrent date: 2019-12-28 13:57:39\nCurrent date: 2019-12-29 09:14:53\nCurrent date: 2019-12-30 03:16:22\nCurrent date: 2019-12-30 19:07:01\nCurrent date: 2019-12-31 13:12:29\nCurrent date: 2020-01-01 09:49:08\nCurrent date: 2020-01-02 07:00:56\nCurrent date: 2020-01-02 21:22:39\nCurrent date: 2020-01-03 09:51:17\nCurrent date: 2020-01-03 19:55:18\nCurrent date: 2020-01-04 10:05:32\nCurrent date: 2020-01-04 22:42:01\nCurrent date: 2020-01-05 10:47:55\nCurrent date: 2020-01-05 19:27:48\nCurrent date: 2020-01-06 04:28:58\nCurrent date: 2020-01-06 17:23:27\nCurrent date: 2020-01-07 04:13:05\nCurrent date: 2020-01-07 15:29:33\nCurrent date: 2020-01-08 00:37:41\nCurrent date: 2020-01-08 04:42:47\nCurrent date: 2020-01-08 11:12:17\nCurrent date: 2020-01-08 18:19:38\nCurrent date: 2020-01-09 02:25:43\nCurrent date: 2020-01-09 15:33:17\nCurrent date: 2020-01-09 23:00:14\nCurrent date: 2020-01-10 11:06:21\nCurrent date: 2020-01-10 20:58:27\nCurrent date: 2020-01-11 07:04:14\nCurrent date: 2020-01-11 18:45:59\nCurrent date: 2020-01-12 08:10:23\nCurrent date: 2020-01-12 19:13:21\nCurrent date: 2020-01-13 09:41:24\nCurrent date: 2020-01-13 20:34:54\nCurrent date: 2020-01-14 09:28:06\nCurrent date: 2020-01-14 19:11:32\nCurrent date: 2020-01-15 07:46:11\nCurrent date: 2020-01-15 17:17:12\nCurrent date: 2020-01-16 05:21:14\nCurrent date: 2020-01-16 16:39:45\nCurrent date: 2020-01-17 05:14:15\nCurrent date: 2020-01-17 17:29:13\nCurrent date: 2020-01-18 09:14:36\nCurrent date: 2020-01-18 22:47:11\nCurrent date: 2020-01-19 17:22:19\nCurrent date: 2020-01-20 09:33:25\nCurrent date: 2020-01-20 20:33:43\nCurrent date: 2020-01-21 12:07:30\nCurrent date: 2020-01-21 19:51:02\nCurrent date: 2020-01-22 08:51:27\nCurrent date: 2020-01-22 18:57:35\nCurrent date: 2020-01-23 08:25:21\nCurrent date: 2020-01-23 17:35:19\nCurrent date: 2020-01-24 04:52:25\nCurrent date: 2020-01-24 16:08:37\nCurrent date: 2020-01-25 02:11:26\nCurrent date: 2020-01-25 15:25:43\nCurrent date: 2020-01-26 03:40:23\nCurrent date: 2020-01-26 18:21:37\nCurrent date: 2020-01-26 22:56:30\nCurrent date: 2020-01-27 11:38:25\nCurrent date: 2020-01-27 19:57:59\nCurrent date: 2020-01-28 10:32:51\nCurrent date: 2020-01-28 19:07:33\nCurrent date: 2020-01-29 06:37:24\nCurrent date: 2020-01-29 17:11:37\nCurrent date: 2020-01-30 02:36:44\nCurrent date: 2020-01-30 11:32:35\nCurrent date: 2020-01-30 17:27:06\nCurrent date: 2020-01-31 00:55:15\nCurrent date: 2020-01-31 08:51:10\nCurrent date: 2020-01-31 16:06:26\nCurrent date: 2020-01-31 21:34:22\nCurrent date: 2020-02-01 06:20:26\nCurrent date: 2020-02-01 16:31:22\nCurrent date: 2020-02-02 01:56:25\nCurrent date: 2020-02-02 11:59:24\nCurrent date: 2020-02-02 22:19:23\nCurrent date: 2020-02-03 08:13:16\nCurrent date: 2020-02-03 16:48:27\nCurrent date: 2020-02-04 00:19:09\nCurrent date: 2020-02-04 09:03:57\nCurrent date: 2020-02-04 16:53:32\nCurrent date: 2020-02-05 02:02:28\nCurrent date: 2020-02-05 11:00:11\nCurrent date: 2020-02-05 19:32:41\nCurrent date: 2020-02-06 03:28:32\nCurrent date: 2020-02-06 13:26:09\nCurrent date: 2020-02-06 20:11:28\nCurrent date: 2020-02-07 05:28:09\nCurrent date: 2020-02-07 15:18:15\nCurrent date: 2020-02-08 00:32:36\nCurrent date: 2020-02-08 12:00:08\nCurrent date: 2020-02-08 22:09:43\nCurrent date: 2020-02-09 10:55:41\nCurrent date: 2020-02-09 22:08:27\nCurrent date: 2020-02-10 08:49:37\nCurrent date: 2020-02-10 18:01:55\nCurrent date: 2020-02-11 03:37:47\nCurrent date: 2020-02-11 14:13:36\nCurrent date: 2020-02-11 22:12:35\nCurrent date: 2020-02-12 09:48:04\nCurrent date: 2020-02-12 18:35:18\nCurrent date: 2020-02-13 04:56:33\nCurrent date: 2020-02-13 14:45:44\nCurrent date: 2020-02-13 23:30:21\nCurrent date: 2020-02-14 11:47:59\nCurrent date: 2020-02-14 21:28:32\nCurrent date: 2020-02-15 11:42:36\nCurrent date: 2020-02-15 23:41:29\nCurrent date: 2020-02-16 12:25:12\nCurrent date: 2020-02-17 01:24:25\nCurrent date: 2020-02-17 12:52:06\nCurrent date: 2020-02-17 22:00:44\nCurrent date: 2020-02-18 09:56:11\nCurrent date: 2020-02-18 19:06:18\nCurrent date: 2020-02-19 05:35:47\nCurrent date: 2020-02-19 15:28:25\nCurrent date: 2020-02-20 01:01:12\nCurrent date: 2020-02-20 11:29:30\nCurrent date: 2020-02-20 20:43:41\nCurrent date: 2020-02-21 08:57:02\nCurrent date: 2020-02-21 18:00:42\nCurrent date: 2020-02-22 06:13:36\nCurrent date: 2020-02-22 19:45:44\nCurrent date: 2020-02-23 11:01:09\nCurrent date: 2020-02-24 01:29:09\nCurrent date: 2020-02-24 13:12:50\nCurrent date: 2020-02-24 21:25:50\nCurrent date: 2020-02-25 09:53:30\nCurrent date: 2020-02-25 18:42:50\nCurrent date: 2020-02-26 07:23:05\nCurrent date: 2020-02-26 17:25:04\nCurrent date: 2020-02-27 03:40:04\nCurrent date: 2020-02-27 13:45:14\nCurrent date: 2020-02-27 22:01:21\nCurrent date: 2020-02-28 07:31:13\nCurrent date: 2020-02-28 16:10:40\nCurrent date: 2020-02-29 02:11:26\nCurrent date: 2020-02-29 13:28:46\nCurrent date: 2020-02-29 22:22:21\nCurrent date: 2020-03-01 10:34:23\nCurrent date: 2020-03-01 20:20:18\nCurrent date: 2020-03-02 07:53:21\nCurrent date: 2020-03-02 15:53:10\nCurrent date: 2020-03-03 00:13:55\nCurrent date: 2020-03-03 10:48:45\nCurrent date: 2020-03-03 18:49:44\nCurrent date: 2020-03-04 04:56:29\nCurrent date: 2020-03-04 14:11:05\nCurrent date: 2020-03-04 22:19:12\nCurrent date: 2020-03-05 10:42:07\nCurrent date: 2020-03-05 18:15:42\nCurrent date: 2020-03-06 03:27:56\nCurrent date: 2020-03-06 13:43:26\nCurrent date: 2020-03-06 22:03:06\nCurrent date: 2020-03-07 08:56:09\nCurrent date: 2020-03-07 19:11:37\nCurrent date: 2020-03-08 06:53:28\nCurrent date: 2020-03-08 18:43:23\nCurrent date: 2020-03-09 05:55:48\nCurrent date: 2020-03-09 14:10:31\nCurrent date: 2020-03-09 21:43:20\nCurrent date: 2020-03-10 08:01:22\nCurrent date: 2020-03-10 16:33:38\nCurrent date: 2020-03-11 02:05:17\nCurrent date: 2020-03-11 11:47:42\nCurrent date: 2020-03-11 17:44:18\nCurrent date: 2020-03-11 23:42:33\nCurrent date: 2020-03-12 05:22:57\nCurrent date: 2020-03-12 14:17:54\nCurrent date: 2020-03-12 19:10:59\nCurrent date: 2020-03-13 01:36:03\nCurrent date: 2020-03-13 08:58:33\nCurrent date: 2020-03-13 15:21:09\nCurrent date: 2020-03-13 20:36:55\nCurrent date: 2020-03-14 04:49:31\nCurrent date: 2020-03-14 14:36:20\nCurrent date: 2020-03-14 20:58:12\nCurrent date: 2020-03-15 08:09:41\nCurrent date: 2020-03-15 16:14:32\nCurrent date: 2020-03-15 23:12:07\nCurrent date: 2020-03-16 07:35:50\nCurrent date: 2020-03-16 14:53:35\nCurrent date: 2020-03-16 19:41:07\nCurrent date: 2020-03-17 02:11:29\nCurrent date: 2020-03-17 10:46:14\nCurrent date: 2020-03-17 16:38:59\nCurrent date: 2020-03-17 22:29:28\nCurrent date: 2020-03-18 07:14:17\nCurrent date: 2020-03-18 14:38:21\nCurrent date: 2020-03-18 18:50:10\nCurrent date: 2020-03-19 02:23:55\nCurrent date: 2020-03-19 10:19:46\nCurrent date: 2020-03-19 16:53:56\nCurrent date: 2020-03-19 23:06:34\nCurrent date: 2020-03-20 08:17:11\nCurrent date: 2020-03-20 16:06:28\nCurrent date: 2020-03-20 23:02:57\nCurrent date: 2020-03-21 08:55:16\nCurrent date: 2020-03-21 18:06:35\nCurrent date: 2020-03-22 04:49:28\nCurrent date: 2020-03-22 13:56:30\nCurrent date: 2020-03-22 21:31:33\nCurrent date: 2020-03-23 06:24:15\nCurrent date: 2020-03-23 15:11:03\nCurrent date: 2020-03-23 21:42:51\nCurrent date: 2020-03-24 06:54:59\nCurrent date: 2020-03-24 13:46:45\nCurrent date: 2020-03-24 17:47:33\nCurrent date: 2020-03-25 00:59:40\nCurrent date: 2020-03-25 08:46:27\nCurrent date: 2020-03-25 10:26:11\n"
    }
   ],
   "source": [
    "# Downloading the data\n",
    "DATA = forceGetData(datesList[1], datesList[0], 'worldnews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "106599\n"
    }
   ],
   "source": [
    "print(len(DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to .csv\n",
    "writeDataToCSV(DATA, 'last3Months.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}